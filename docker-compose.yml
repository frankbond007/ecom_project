version: '3.8'

services:
  zookeeper:
    container_name: zookeeper
    image: wurstmeister/zookeeper:latest
    ports:
      - "2181:2181"

  kafka-broker:
    container_name: kafka-broker
    image: wurstmeister/kafka:latest
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_NUM_PARTITIONS: 2
    depends_on:
      - zookeeper

  kafka-broker-2:
    container_name: kafka-broker-2
    image: wurstmeister/kafka:latest
    ports:
      - "9093:9093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker-2:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9093
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_NUM_PARTITIONS: 2
    depends_on:
      - zookeeper
      - kafka-broker

  debezium:
    container_name: debezium
    image: debezium/connect:latest
    ports:
      - "8083:8083"
    environment:
      BOOTSTRAP_SERVERS: kafka-broker:9092,kafka-broker-2:9093
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: debezium_config
      OFFSET_STORAGE_TOPIC: debezium_offsets
      STATUS_STORAGE_TOPIC: debezium_status
      KEY_CONVERTER_SCHEMAS_ENABLE: false
      VALUE_CONVERTER_SCHEMAS_ENABLE: false
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_REST_ADVERTISED_HOST_NAME: debezium
      CONNECT_PLUGIN_PATH: /kafka/connect
    volumes:
      - debezium-plugins:/kafka/connect
    depends_on:
      - kafka-broker
      - kafka-broker-2

  mysql:
    container_name: mysql
    image: mysql:8.0
    command: --default-authentication-plugin=mysql_native_password
    restart: always
    ports:
      - "3306:3306"
    environment:
      - MYSQL_ROOT_PASSWORD=12345678
      - MYSQL_DATABASE=ecommerce
      - MYSQL_USER=user
      - MYSQL_PASSWORD=12345678
    volumes:
      - mysql-data:/var/lib/mysql
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql

  clickhouse:
    container_name: clickhouse
    image: yandex/clickhouse-server:latest
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - clickhouse-data:/var/lib/clickhouse

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    depends_on:
      - kafka-broker
      - kafka-broker-2
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-broker:9092,kafka-broker-2:9093

  kafka-consumer:
    container_name: kafka-consumer
    image: python:3.9-slim
    depends_on:
      - kafka-broker
      - kafka-broker-2
      - clickhouse
      - mysql
      - debezium
    volumes:
      - ./app:/app
    command: /bin/bash -c "apt-get update && apt-get install -y curl jq build-essential && apt-get install -y clickhouse-client && chmod +x /app/initialize_connector.sh && /app/initialize_connector.sh"

  postgres:
    container_name: postgres
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - postgres-db-data:/var/lib/postgresql/data

  airflow-init:
    container_name: airflow-init
    build:
      context: .
      dockerfile: Dockerfile.airflow
    image: custom-airflow:latest
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    entrypoint: /bin/bash -c "airflow db upgrade && airflow users create -r Admin -u admin -p admin -e admin@example.com -f Admin -l User && airflow db check && exec airflow scheduler"

  airflow-webserver:
    container_name: airflow-webserver
    build:
      context: .
      dockerfile: Dockerfile.airflow
    image: custom-airflow:latest
    depends_on:
      - airflow-init
    ports:
      - "8081:8080"
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    entrypoint: /bin/bash -c "airflow webserver"
  cube:
    image: cubejs/cube:latest
    ports:
      - 4000:4000
      - 15432:15432
    environment:
      - CUBEJS_DEV_MODE=true
    volumes:
      - .:/cube/conf

volumes:
  mysql-data:
  clickhouse-data:
  debezium-plugins:
  postgres-db-data:
  airflow-logs:
